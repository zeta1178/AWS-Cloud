{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Students Do: Credit Risk Classification with Amazon SageMaker\n","\n","* **Dataset:** German Credit Risk Dataset - Prof. Dr. Hans Hofmann (original source: [ics.uci.edu](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)), download: [Kaggle](https://www.kaggle.com/kabure/german-credit-data-with-risk/downloads/german_credit_data.csv/1))\n","\n","* **Goal:** Classify the credit risk of a person as described by a given set of input features.\n","\n","**Note:** You should import and run this notebook into your notebook intance on Amazon SageMaker."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Initial imports\nimport numpy as np\nimport pandas as pd\nfrom path import Path\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n"},{"cell_type":"markdown","metadata":{},"source":["## Loading the data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Upload the german_credit_data.csv file (located in ../Resources/) through through JupyterLab\nfile_path = Path(\"Data/german_credit_data.csv\")\ndf = pd.read_csv(file_path, index_col=0)\ndf.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Creating a DataFrame with the features (include all columns except \"Risk\")\nfeatures_df = df.drop(\"Risk\", axis=1)\nfeatures_df.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Creating a DataFrame with the target data (The \"Risk\" column)\ntarget_df = pd.DataFrame(df[\"Risk\"])\ntarget_df.head()\n"},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation\n","\n","A logistic regression model will be trained using all the input features.\n","\n","* `X` is the predictor variable vector with the values of all features.\n","* `Y` is the target variable vector with the risk result."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Encode the categorical features (One-hot encode)\nfeatures_enc = pd.get_dummies(features_df)\nfeatures_enc.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# ignore DataConversionWarning messages\nimport warnings\nfrom sklearn.exceptions import DataConversionWarning\n\nwarnings.filterwarnings(action=\"ignore\", category=DataConversionWarning)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Scale the features\nfrom sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler().fit(features_enc)\nscaler\nprint(scaler.mean_[:5])\nprint(scaler.scale_[:5])\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"features_enc_scaled = scaler.transform(features_enc)\nfeatures_enc_scaled\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"target_enc = pd.get_dummies(target_df)\ntarget_enc.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"X = features_enc_scaled\nY = target_enc[\"Risk_bad\"].values.reshape(-1)  # 0 = Good, 1 = Bad Risk\nprint(X[:5])\nprint(Y[:5])\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Split the data in training and testing sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n"},{"cell_type":"markdown","metadata":{},"source":["## Machine Learning Model Creation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"bucket = \"your_s3_bucket_name_here\"\nprefix = \"german-credit-risk\"\n\n# Amazon SageMaker and related imports\nimport sagemaker\nimport sagemaker.amazon.common as smac\nfrom sagemaker.predictor import csv_serializer, json_deserializer\nfrom sagemaker import get_execution_role\nimport boto3  # AWS Python sdk\n\nimport os\nimport io\nimport json\n\n# AWS IAM role\nrole = get_execution_role()\n"},{"cell_type":"markdown","metadata":{},"source":["### Uploading Training Data to Amazon S3\n","\n","In order to train your machine learning model using Amazon SageMaker, the training data should passed through an Amazon S3 Bucket formatted as a [protobuf recordIO format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-serialization).\n","\n","The profobuf recordIO format, is a method to serialize structured data (similar to `JSON`), to allow different applications to communicate with each other or for storing data.\n","\n","Using the profobuf recordIO format, allows you to take advantage of _Pipe mode_ when training the algorithms that support it. In _Pipe mode_, your training job streams data directly from Amazon S3. Streaming can provide faster start times for training jobs and better throughput.\n","\n","The following code converts the training data as a Protocol Buffer, next the data is uploaded to the Amazon S3 bucket."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Encode the training data as Protocol Buffer\n\n\n# Upload encoded training data to Amazon S3\n\n"},{"cell_type":"markdown","metadata":{},"source":["#### Upload Test Data to Amazon S3\n","\n","If you provide test data, the algorithm logs include the test score for the final model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Encode the testing data as Protocol Buffer\n\n\n# Upload encoded testing data to Amazon S3\n\n"},{"cell_type":"markdown","metadata":{},"source":["### Training the Machine Learning Model\n","\n","Once you have uploaded your data to Amazon S3, it's time to train the machine learning model. In this activity, you will use the Amazon SageMaker's [_linear learner algorithm_](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) to run a linear regression prediction model.\n","\n","You can learn more about the diferent Amazon SageMaker built-in algorithms [in this page](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\n","\n","First, an intance of the linear learner algorithm is created."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Create an instance of the linear learner algorithm\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\n\ncontainer = \n"},{"cell_type":"markdown","metadata":{},"source":["Next, the estimator container is created in an AWS EC2 instance using a `ml.m4.xlarge`.\n","\n","**Note:** This step might take a few minutes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Start the Amazon SageMaker session\nsess = \n\n# Create an instance of the linear learner estimator\nlinear = sagemaker.estimator.Estimator(\n    container,\n    role,\n    train_instance_count=1,\n    train_instance_type=\"ml.m4.xlarge\",\n    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n    sagemaker_session=sess,\n)\n\n# Get the dimension of the feature-input vector\nfeature_dim = len(X[:1][0])\n\n\n# Define linear learner hyperparameters\n# Note how in this case we use: predictor_type='binary_classifier' # (credit risk: good or bad)\nlinear.set_hyperparameters(\n    feature_dim=feature_dim, mini_batch_size=200, predictor_type=\"binary_classifier\"\n)\n\n# Fitting the linear learner model with the training data\nlinear.fit({\"train\": s3_train_data, \"test\": s3_test_data})\n"},{"cell_type":"markdown","metadata":{},"source":"### Deploying the Model to Make Predictions\n\nIn this section, the `linear-learner` model that was trained will be used to make predictions of credit risk. Deploy the model using a `ml.t2.medium` instance type.\n\n**Note:** This step might take a few minutes."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# An instance of the linear-learner predictor is created\nlinear_predictor = \n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Linear predictor configurations\nlinear_predictor.content_type = \"text/csv\"\nlinear_predictor.serializer = csv_serializer\nlinear_predictor.deserializer = json_deserializer\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Making some predictions using the test data.\nresult = linear_predictor.predict(X_test)\ny_predictions = np.array(\n    [np.uint8(r[\"predicted_label\"]) for r in result[\"predictions\"]]\n)\ny_predictions\n"},{"cell_type":"markdown","metadata":{},"source":["### Model Evaluation\n","\n","To evaluate the model, we create a confusion matrix to compare the cases where each predicted value matches the expected test-value and when not."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pandas as pd\n\n# Encode the predictios results as 0 = Good, 1 = Bad Risk\ncat_test = np.array([\"Good\" if x == 0 else \"Bad\" for x in Y_test])\ncat_pred = np.array([\"Good\" if x == 0 else \"Bad\" for x in y_predictions])\n\n# Create the confusion matrix\npd.crosstab(cat_test, cat_pred, rownames=[\"actuals\"], colnames=[\"predictions\"])\n\n"},{"cell_type":"markdown","metadata":{},"source":["The model is also evaluated using the `sklearn` metrics module. The following metrics are calculated:\n","\n","* [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n","\n","* [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n","\n","* [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nprint(f\"accuracy_score: {accuracy_score(Y_test,y_predictions)}\\n\\n\")\nprint(\n    f\"sklearn's confusion_matrix: \\n\\n{confusion_matrix(Y_test, y_predictions, labels=[0, 1])}\\n\\n\"\n)\nprint(\n    f\"classification_report: \\n\\n{classification_report(Y_test, y_predictions, target_names=['Good', 'Bad'])}\\n\\n\"\n)\n"},{"cell_type":"markdown","metadata":{},"source":["Finally the end point is deleted to avoid additional AWS resources usage."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Delete Amazon SageMaker end-point\n\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}