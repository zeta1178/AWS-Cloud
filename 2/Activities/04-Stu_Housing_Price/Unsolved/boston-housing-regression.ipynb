{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Students Do: Housing Price Prediction on SageMaker\n","\n","* **Dataset:** [Boston house prices dataset - Harrison, D. and Rubinfeld, D.L.](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)\n","* **Goal:** Predict the price of a house using linear regression given certain input features.\n","\n","**Note:** You should import and run this notebook into your notebook instance on Amazon SageMaker."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Initial imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n"},{"cell_type":"markdown","metadata":{},"source":["## Loading the Boston House Price Data from `sklearn`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Loading the Boston house price data from sklearn\nfrom sklearn.datasets import load_boston\n\nboston_dataset = load_boston()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"dir(boston_dataset)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"print(boston_dataset.DESCR)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Creating a DataFrame with the Boston House Data features\nfeatures_df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\nfeatures_df.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Creating a DataFrame with the target data\ntarget_df = pd.DataFrame(boston_dataset.target)\ntarget_df.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Plot target distribution\ntarget_df.plot.hist(bins=20)\n"},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation\n","\n","A linear regression model will be trained using the average number of rooms per dwelling (`RM`) to predict the house price.\n","\n","* `X` is the predictor variable vector with the values of `RM`.\n","* `Y` is the target variable vector with the house prices value."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Define the X and Y vectors\nX = \nY = \n\n# Split the data in training and testing sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = \n"},{"cell_type":"markdown","metadata":{},"source":["## Machine Learning Model Creation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"bucket = \"your_s3_bucket_name_here\"\nprefix = \"boston-housing-regression\"\n\n# Amazon SageMaker and related imports\nimport sagemaker\nimport sagemaker.amazon.common as smac\nfrom sagemaker.predictor import csv_serializer, json_deserializer\nfrom sagemaker import get_execution_role\nimport boto3  # AWS Python sdk\n\nimport os\nimport io\nimport time\nimport json\nimport re\n\n# AWS IAM role\nrole = get_execution_role()\n"},{"cell_type":"markdown","metadata":{},"source":["### Uploading Training Data to Amazon S3\n","\n","In order to train your machine learning model using Amazon SageMaker, the training data should passed through an Amazon S3 Bucket formatted as a [protobuf recordIO format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-serialization).\n","\n","The profobuf recordIO format, is a method to serialize structured data (similar to `JSON`), to allow different applications to communicate with each other or for storing data.\n","\n","Using the profobuf recordIO format, allows you to take advantage of _Pipe mode_ when training the algorithms that support it. In _Pipe mode_, your training job streams data directly from Amazon S3. Streaming can provide faster start times for training jobs and better throughput.\n","\n","The following code converts the training data as a Protocol Buffer, next the data is uploaded to the Amazon S3 bucket."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Encode the training data as Protocol Buffer\nbuf = io.BytesIO()\nvectors = np.array(X_train).astype(\"float32\")\nlabels = np.array(Y_train).astype(\"float32\")\nsmac.write_numpy_to_dense_tensor(buf, vectors, labels)\nbuf.seek(0)\n\n# Upload encoded training data to Amazon S3\nkey = \"linear_train.data\"\nboto3.resource(\"s3\").Bucket(bucket).Object(\n    os.path.join(prefix, \"train\", key)\n).upload_fileobj(buf)\ns3_train_data = \"s3://{}/{}/train/{}\".format(bucket, prefix, key)\nprint(\"Training data uploaded to: {}\".format(s3_train_data))\n"},{"cell_type":"markdown","metadata":{},"source":["#### Upload Test Data to Amazon S3\n","\n","If you provide test data, the algorithm logs include the test score for the final model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Encode the testing data as Protocol Buffer\n\n\n# Upload encoded testing data to Amazon S3\n\n"},{"cell_type":"markdown","metadata":{},"source":["### Training the Machine Learning Model\n","\n","Once you have uploaded your data to Amazon S3, it's time to train the machine learning model. In this activity, you will use the Amazon SageMaker's [_linear learner algorithm_](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) to run a linear regression prediction model.\n","\n","You can learn more about the different Amazon SageMaker built-in algorithms [in this page](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\n","\n","First, an instance of the linear learner algorithm is created."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Create an instance of the linear learner algorithm\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\n\ncontainer = get_image_uri(boto3.Session().region_name, \"linear-learner\")\n"},{"cell_type":"markdown","metadata":{},"source":["Next, the estimator container is created in an AWS EC2 instance (@ train_instance_type) using a `ml.m4.xlarge`.\n","\n","**Note:** This step might take a few minutes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Start the Amazon SageMaker session\nsess = sagemaker.Session()\n\n# Create an instance of the linear learner estimator\nlinear = sagemaker.estimator.Estimator(\n    container,\n    role,\n    train_instance_count=1,\n    train_instance_type=\"ml.m4.xlarge\",\n    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n    sagemaker_session=sess,\n)\n\n# Define linear learner hyperparameters\nlinear.set_hyperparameters(\n    feature_dim=1,\n    mini_batch_size=100,\n    predictor_type=\"regressor\",\n    epochs=10,\n    num_models=32,\n    loss=\"absolute_loss\",\n)\n\n# Fitting the linear learner model with the training data\nlinear.fit({\"train\": s3_train_data, \"test\": s3_test_data})\n"},{"cell_type":"markdown","metadata":{},"source":"### Deploying the Model to Make Predictions\n\nIn this section, the `linear-learner` model that was trained will be used to make predictions of house prices. Deploy the model using a `ml.t2.medium` instance type.\n\n**Note:** This step might take a few minutes."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# An instance of the linear-learner predictor is created\nlinear_predictor = linear.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Linear predictor configurations\nlinear_predictor.content_type = \"text/csv\"\nlinear_predictor.serializer = csv_serializer\nlinear_predictor.deserializer = json_deserializer\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Making some predictions using the test data.\nresult = linear_predictor.predict(X_test)\ny_predictions = np.array([r[\"score\"] for r in result[\"predictions\"]])\ny_predictions\n"},{"cell_type":"markdown","metadata":{},"source":["### Model Evaluation\n","\n","To evaluate the model, a plot to contrast the predicted housing prices values versus the real values is created. Additionally, the `RMSE` and `R2` scores are calculated."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Plotting predicted Vs. actual values\nplt.plot(np.array(Y_test), label=\"actual\")\nplt.plot(y_predictions, label=\"predict\")\nplt.legend()\nplt.show()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Calculating the RMSE and R2 scores\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nrmse = np.sqrt(mean_squared_error(Y_test, y_predictions))\nr2 = r2_score(Y_test, y_predictions)\n\nprint(\"RMSE: {}\".format(rmse))\nprint(\"R2 score: {}\".format(r2))\n"},{"cell_type":"markdown","metadata":{},"source":["Finally the end point is deleted to avoid additional AWS resources usage."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Delete Amazon SageMaker end-point\nsagemaker.Session().delete_endpoint(linear_predictor.endpoint)\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}